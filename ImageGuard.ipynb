{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ClaretWheel1481/ImageGuard-dev/blob/main/ImageGuard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 导入所需库"
      ],
      "metadata": {
        "id": "PLDsdFZVA7Qk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mb4iU28v8X2T"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from urllib.parse import urlparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from PIL import ImageFile, Image\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCqoekVf8hjk"
      },
      "source": [
        "# 多线程下载数据集图片"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhTfZUo78gOV"
      },
      "outputs": [],
      "source": [
        "# 创建文件夹\n",
        "def create_directory(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrwAULFE8lHz"
      },
      "outputs": [],
      "source": [
        "def download_image(url, save_dir):\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        img_name = os.path.basename(urlparse(url).path)\n",
        "        img_path = os.path.join(save_dir, img_name)\n",
        "        with open(img_path, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "        print(f\"Downloaded {img_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to download {url}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmkmfL3K8owb"
      },
      "outputs": [],
      "source": [
        "def download_dataset(urls_file, save_dir):\n",
        "    create_directory(save_dir)\n",
        "    with open(urls_file, 'r') as f:\n",
        "        urls = f.read().splitlines()\n",
        "    with ThreadPoolExecutor(max_workers=128) as executor:\n",
        "        for url in urls:\n",
        "            executor.submit(download_image, url, save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6At-P3B8qVE",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "datasets = ['neutral', 'porn']\n",
        "for dataset in datasets:\n",
        "    urls_file = f'drive/MyDrive/数据集/data/train/{dataset}/urls_{dataset}.txt'\n",
        "    save_dir = f'dataset/{dataset}'\n",
        "    download_dataset(urls_file, save_dir)\n",
        "    # TODO: 检测URL是否可正常访问，不可用则在txt中移除"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg2QvGDd-9vj"
      },
      "source": [
        "# 加载数据集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vftfiLg7_DfS"
      },
      "outputs": [],
      "source": [
        "# 自定义ImageFolder类以跳过无效图像\n",
        "class CustomImageFolder(datasets.ImageFolder):\n",
        "    def __getitem__(self, index):\n",
        "        while True:\n",
        "            try:\n",
        "                sample, target = super(CustomImageFolder, self).__getitem__(index)\n",
        "                if sample is not None:\n",
        "                    return sample, target\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to load image {self.imgs[index][0]}: {e}\")\n",
        "                index = (index + 1) % len(self.imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1_4fCb-_FOC"
      },
      "outputs": [],
      "source": [
        "# 加载图片数据方法\n",
        "def pil_loader(path):\n",
        "    try:\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load image {path}: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: 检测所有图像是否可正常打开"
      ],
      "metadata": {
        "id": "G6dNSXaqbFfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzAsXxRl_Hu7"
      },
      "outputs": [],
      "source": [
        "# 数据预处理\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize(1099),\n",
        "        transforms.RandomResizedCrop(1099, scale=(0.8, 1.0), ratio=(3/4, 4/3)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(1099),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EVm1dN0_JmC"
      },
      "outputs": [],
      "source": [
        "# 加载数据集\n",
        "train_dataset = CustomImageFolder('dataset', transform=data_transforms['train'], loader=pil_loader)\n",
        "val_dataset = CustomImageFolder('drive/MyDrive/数据集/data/validation', transform=data_transforms['val'], loader=pil_loader)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n",
        "class_names = train_dataset.classes\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 构建模型"
      ],
      "metadata": {
        "id": "gsiQ7n5PBKuC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y27ZKGv-_Qgy"
      },
      "outputs": [],
      "source": [
        "# 构建模型\n",
        "class ImageGuard(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageGuard, self).__init__()\n",
        "\n",
        "        # RESNET50\n",
        "        self.base_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "        self.base_model.fc = nn.Sequential(\n",
        "            nn.Linear(self.base_model.fc.in_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 2),\n",
        "            # TODO: 目前只有两种分类，不使用Softmax\n",
        "            # nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcxQ-HT8_cFy"
      },
      "outputs": [],
      "source": [
        "model = ImageGuard()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5Rqz5ydBIuZ"
      },
      "outputs": [],
      "source": [
        "# 交叉熵损失函数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 优化器\n",
        "# TODO: Adam优化器相对更稳定，RMSprop需要控制学习率，未来调优\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=0.002, weight_decay=1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 训练模型"
      ],
      "metadata": {
        "id": "p5u2eKAYBMuB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFth-uirBMjL"
      },
      "outputs": [],
      "source": [
        "# 训练模型\n",
        "def train_model(model, criterion, optimizer, num_epochs):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        loop = tqdm(enumerate(train_loader),total=len(train_loader))\n",
        "\n",
        "        for step, data in loop:\n",
        "            images,labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            with torch.set_grad_enabled(True):\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "            loop.set_description(f'Epoch [{epoch + 1}/{num_epochs}]')\n",
        "            loop.set_postfix(loss=running_loss / dataset_sizes['train'])\n",
        "\n",
        "        validate_model(model)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izxacNC3BOwJ"
      },
      "outputs": [],
      "source": [
        "# 评估性能\n",
        "def validate_model(model):\n",
        "    model.eval()\n",
        "    corrects = 0\n",
        "\n",
        "    for data in val_loader:\n",
        "        images,labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(images)\n",
        "            preds = torch.argmax(outputs, 1)\n",
        "            corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    print(f\"correct: {corrects/len(val_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OK1QxvnBRIC"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"训练模式:{device}\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsnQhstFBTUp"
      },
      "outputs": [],
      "source": [
        "# 训练\n",
        "print(\"开始训练\")\n",
        "print(\"-\" * 20)\n",
        "model = train_model(model, criterion, optimizer, num_epochs=2)\n",
        "if not os.path.exists('model'):\n",
        "    os.makedirs('model')\n",
        "torch.save(model.state_dict(), 'model/image_guard_v2.pth')\n",
        "print(\"Model saved.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "13R9HTDj8fX3VCow5JnNIU50_eunK7sph",
      "authorship_tag": "ABX9TyMNGWAPu5L1HcJPlAAsEuVY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}